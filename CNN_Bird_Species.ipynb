{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84e265c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import os\n",
    "from PIL import Image\n",
    "# to install pytorch, follow instructions on https://pytorch.org/get-started/locally/\n",
    "# if CUDA is installed, this should allow GPU training\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "# -> pip install torchsummary\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba3999fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split complete:\n",
      "Train set: 2272 images\n",
      "Validation set: 569 images\n",
      "Label map: {'Blackbird': 0, 'Bluetit': 1, 'Carrion_Crow': 2, 'Chaffinch': 3, 'Coal_Tit': 4, 'Collared_Dove': 5, 'Dunnock': 6, 'Feral_Pigeon': 7, 'Goldfinch': 8, 'Great_Tit': 9, 'Greenfinch': 10, 'House_Sparrow': 11, 'Jackdaw': 12, 'Long_Tailed_Tit': 13, 'Magpie': 14, 'Robin': 15, 'Song_Thrush': 16, 'Starling': 17, 'Wood_Pigeon': 18, 'Wren': 19}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Path to expanded dataset\n",
    "dataset_dir = r\"C:\\Users\\antoi\\Documents\\Nell_Antoine_Project\\DATA\"\n",
    "\n",
    "# Step 1: Load images and labels\n",
    "def load_images_from_directory(directory, target_size=(1024, 1024)):\n",
    "    images = []\n",
    "    labels = []\n",
    "    class_names = sorted(os.listdir(directory))  # Ensure label order is consistent\n",
    "    class_to_index = {name: idx for idx, name in enumerate(class_names)}\n",
    "\n",
    "    for class_name in class_names:\n",
    "        class_path = os.path.join(directory, class_name)\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue\n",
    "\n",
    "        for img_name in os.listdir(class_path):\n",
    "            img_path = os.path.join(class_path, img_name)\n",
    "            try:\n",
    "                img = Image.open(img_path).convert(\"RGB\")\n",
    "                img = img.resize(target_size)\n",
    "                images.append(np.array(img))\n",
    "                labels.append(class_to_index[class_name])\n",
    "            except Exception as e:\n",
    "                print(f\"Skipping {img_path}: {e}\")\n",
    "\n",
    "    return np.array(images), np.array(labels), class_to_index\n",
    "\n",
    "images, labels, label_map = load_images_from_directory(dataset_dir)\n",
    "\n",
    "# Step 2: Split into training and validation sets\n",
    "train_images, val_images, train_labels, val_labels = train_test_split(\n",
    "    images, labels, test_size=0.2, stratify=labels, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Dataset split complete:\")\n",
    "print(f\"Train set: {len(train_images)} images\")\n",
    "print(f\"Validation set: {len(val_images)} images\")\n",
    "print(\"Label map:\", label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce897c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a set of data augmentation transformations\n",
    "transform = transforms.Compose([\n",
    "    # transforms.RandomRotation(20, fill=(255, 255, 255)),  # Random rotation with white border\n",
    "    transforms.RandomAffine(20, translate=(0.2, 0.2), fill=(255, 255, 255)),  # Random shifts with white border\n",
    "    transforms.RandomHorizontalFlip(),  # Random horizontal flips\n",
    "    transforms.ColorJitter(brightness=(0.8, 1.2)),  # Random brightness adjustment\n",
    "    transforms.ToTensor()  # Convert image to tensor\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "# Apply the transformations to the training dataset\n",
    "class AugmentedDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.fromarray(self.images[idx].astype('uint8'))\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# Create the augmented dataset\n",
    "augmented_dataset = AugmentedDataset(train_images, train_labels, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8ecf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BirdSpeciesCNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BirdSpeciesCNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)  # Max pooling after conv1\n",
    "\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)  # Max pooling after conv2\n",
    "\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)  # Max pooling after conv3\n",
    "\n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)  # Max pooling after conv4\n",
    "\n",
    "        # Use a dummy input to calculate the size\n",
    "        with torch.no_grad():\n",
    "            dummy_input = torch.randn(1, 3, 256, 256)  # Batch size 1\n",
    "            x = F.relu(self.conv1(dummy_input))\n",
    "            x = self.pool1(x)\n",
    "            x = F.relu(self.conv2(x))\n",
    "            x = self.pool2(x)\n",
    "            x = F.relu(self.conv3(x))\n",
    "            x = self.pool3(x)\n",
    "            x = F.relu(self.conv4(x))\n",
    "            x = self.pool4(x)\n",
    "            self.flatten_size = x.numel()\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(self.flatten_size, 256)\n",
    "        self.dropout = nn.Dropout(p=0.5)  # Add dropout layer with 50% probability\n",
    "        self.fc2 = nn.Linear(256, 20)  # Assuming 20 classes\n",
    "        \n",
    "        # Initialize weights\n",
    "        self._initialize_weights()\n",
    "        \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool3(x)\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.pool4(x)\n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)  # Apply dropout\n",
    "        x = self.fc2(x)  # No softmax needed\n",
    "        return x\n",
    "\n",
    "# Example of model instantiation\n",
    "model = SimplifiedCNNModel()\n",
    "print(model)\n",
    "\n",
    "# Move model to GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
